{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def svm_loss_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Structured SVM loss function, naive implementation (with loops).\n",
    "\n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - reg: (float) regularization strength\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)  # initialize the gradient as zero\n",
    "\n",
    "    # compute the loss and the gradient\n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    loss = 0.0\n",
    "    for i in range(num_train):\n",
    "        scores = X[i].dot(W)\n",
    "        correct_class_score = scores[y[i]]\n",
    "        for j in range(num_classes):\n",
    "            if j == y[i]:\n",
    "                continue\n",
    "            margin = scores[j] - correct_class_score + 1  # note delta = 1\n",
    "            if margin > 0:\n",
    "                loss += margin\n",
    "                dW[:, j] += X[i]\n",
    "                dW[:, y[i]] -= X[i]\n",
    "\n",
    "    # Right now the loss is a sum over all training examples, but we want it\n",
    "    # to be an average instead so we divide by num_train.\n",
    "    loss /= num_train\n",
    "    dW /= num_train\n",
    "\n",
    "    # Add regularization to the loss and gradient.\n",
    "    loss += 0.5 * reg * np.sum(W * W)\n",
    "    dW += reg * W\n",
    "\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "某样本 $i$ 在类别 $j$ 上的得分：\n",
    "\n",
    "$$\n",
    "s_j = X_i W_{:,j} \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "损失函数：\n",
    "\n",
    "$$\n",
    "L_i = \\sum_{j \\neq y_i}^C \\max(0, s_j - s_{y_i} + 1) \\\\\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "+ $C$ 是类别数\n",
    "+ $s_{y_i}$ 是样本 $i$ 在正确类别 $y_i$ 上的分数\n",
    "\n",
    "\n",
    "总损失：\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^N L_i + \\frac{\\lambda}{2} \\sum_j \\sum_{k=1}^C W_{j,k}^2\n",
    "$$\n",
    "\n",
    "其中： \n",
    "\n",
    "+ $N$ 是样本数\n",
    "+ $\\frac{\\lambda}{2} \\sum_j \\sum_{k=1}^C W_{j,k}^2$ 是正则项， $\\lambda$ 是正则化强度\n",
    "\n",
    "---\n",
    "\n",
    "当 $j \\neq y_i$ 时：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial (s_j - s_{y_i} + 1)}{\\partial W_{:,k}} &= \\frac{\\partial s_j}{\\partial W_{:,k}} - \\frac{\\partial s_{y_i}}{\\partial W_{:,k}} \\\\ &= \\frac{\\partial (X_i W_{:,j})}{\\partial W_{:,k}} - \\frac{\\partial (X_i W_{:,y_i})}{\\partial W_{:,k}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "+ 当 $k \\neq y_i$ 时， $\\frac {\\partial (X_i W_{:,y_i})}{\\partial W_{:,k}} = 0$ ，此时：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (s_j - s_{y_i} + 1)}{\\partial W_{:,k}} = X_i\n",
    "$$\n",
    "\n",
    "\n",
    "+ 当 $k = y_i$ 时：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (s_j - s_{y_i} + 1)}{\\partial W_{:,k}} = -X_i\n",
    "$$\n",
    "\n",
    "整理得：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L_i}{\\partial W_{:,k}} = -X_{i,y_i} + \\sum_{k \\neq y_i, s_k - s_{y_i} + 1 > 0}^C X_{i,k}\n",
    "$$\n",
    "\n",
    "用字母 $j$ 代替字母 $k$得：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L_i}{\\partial W_{:,j}} = -X_{i,y_i} + \\sum_{j \\neq y_i, s_j - s_{y_i} + 1 > 0}^C X_{i,j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "最后：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} = \\frac{1}{N} \\frac{\\partial L_i}{\\partial W_{:,j}} + \\lambda W\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
